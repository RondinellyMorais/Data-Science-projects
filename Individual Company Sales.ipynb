{"cells":[{"metadata":{},"cell_type":"markdown","source":["# 1. <a id='Introduction'>Introduction "]},{"metadata":{},"cell_type":"markdown","source":["![foto](https://theyellowcarcompany.com/wp-content/uploads/2019/04/The_Yellow_Car_Company_Sales_TYCC-930x550.jpg)"]},{"metadata":{},"cell_type":"markdown","source":["### The \"Individual Company Sales\" dataset is a very interesting example of how we can use a variety of customer information to predict the likelihood that he will buy a specific product or not. The product in question is generic so that our analysis can theoretically be applied to any product"]},{"metadata":{},"cell_type":"markdown","source":["### This dataset includes about 40,000 rows and 15 feature variables. Each row corresponds to a customer infomation, and includes the variables:\n","\n","### 1. flag: Whether the customer has bought the target product or not\n","\n","### 2. gender: Gender of the customer\n","\n","### 3. education: Education background of customer\n","\n","### 4. house_val: Value of the residence the customer lives in\n","\n","### 5. age: Age of the customer by group\n","\n","### 6. online: Whether the customer had online shopping experience or not\n","\n","### 7. customer_psy: Variable describing consumer psychology based on the area of residence\n","\n","### 8. marriage: Marriage status of the customer\n","\n","### 9. children: Whether the customer has children or not\n","\n","### 10. occupation: Career information of the customer\n","\n","### 11. mortgage: Housing Loan Information of customers\n","\n","### 12. house_own: Whether the customer owns a house or not\n","\n","### 13. region: Information on the area in which the customer are located\n","\n","### 14. car_prob: The probability that the customer will buy a new car(1 means the maximum possible）\n","\n","### 15. fam_income: Family income Information of the customer(A means the lowest, and L means the highest)"]},{"metadata":{},"cell_type":"markdown","source":["# 2. <a id='importing'>Importing the necessary libraries"]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","        \n","# Disable warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Import plotting modules\n","!pip install chart-studio\n","import seaborn as sns\n","sns.set()\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker\n","import plotly.express as px\n","from plotly.offline import iplot\n","from matplotlib import rcParams\n","\n","import chart_studio.plotly as py\n","import plotly.graph_objs as go\n","import cufflinks\n","cufflinks.go_offline()\n","cufflinks.set_config_file(world_readable=True, theme='pearl')\n","%matplotlib inline\n","\n","warnings.filterwarnings(\"ignore\")\n","import plotly.figure_factory as ff\n","from colorama import Fore, Back, Style \n","\n","# Import encoder library\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import LabelEncoder \n","\n","# Algorithms\n","from sklearn import linear_model\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import Perceptron\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.naive_bayes import GaussianNB"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: chart-studio in c:\\users\\rondi\\anaconda3\\lib\\site-packages (1.1.0)\nRequirement already satisfied: requests in c:\\users\\rondi\\anaconda3\\lib\\site-packages (from chart-studio) (2.25.1)\nRequirement already satisfied: plotly in c:\\users\\rondi\\anaconda3\\lib\\site-packages (from chart-studio) (4.11.0)\nRequirement already satisfied: six in c:\\users\\rondi\\anaconda3\\lib\\site-packages (from chart-studio) (1.15.0)\nRequirement already satisfied: retrying>=1.3.3 in c:\\users\\rondi\\anaconda3\\lib\\site-packages (from chart-studio) (1.3.3)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\rondi\\anaconda3\\lib\\site-packages (from requests->chart-studio) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\rondi\\anaconda3\\lib\\site-packages (from requests->chart-studio) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rondi\\anaconda3\\lib\\site-packages (from requests->chart-studio) (1.26.2)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\rondi\\anaconda3\\lib\\site-packages (from requests->chart-studio) (2020.12.5)\n"]},{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["# 3. <a id='reading'>Reading the dataset.csv"]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["# load data\n","df = pd.read_csv('../input/individual-company-sales-data/sales_data.csv')\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/individual-company-sales-data/sales_data.csv'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-2-a7940e8c540b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/individual-company-sales-data/sales_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \"\"\"\n\u001b[1;32m-> 1357\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    640\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/individual-company-sales-data/sales_data.csv'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(Fore.BLUE + 'Data information ....................',Style.RESET_ALL)\n","print(df.info())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["for i in df.columns:\n","    print(i, df[i].unique())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 4. <a id='basic'>Basic Data Exploration"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df['gender'] = df.gender.replace('U', np.NaN)\n","df['age'] = df.age.replace('1_Unk', np.NaN)\n","df['child'] = df.child.replace('U', np.NaN)\n","df['child'] = df.child.replace('0', np.NaN)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Fraction of missing values\n","df.isnull().sum() / df.shape[0] * 100"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Show the outliers in 'house_val'\n","plt.figure(figsize = (12, 8))\n","sns.boxplot(data= df, x = 'house_val')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Using quantile method to eliminate outliers"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Applying the quantile method\n","hi_q1 = df['house_val'].quantile(.25)\n","hi_q3 =df['house_val'].quantile(.75)\n","iqr = hi_q3 - hi_q1"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["hi_up = hi_q3 + 1.5*iqr\n","hi_down = hi_q1 - 1.5*iqr"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df0 = df[(df['house_val']> hi_down) & (df['house_val'] < hi_up)]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Show 'house_val' without outliers\n","plt.figure(figsize=(12,8))\n","sns.boxplot(data= df0, x = 'house_val')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Assigning new dataset for encoder\n","dff = df0"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Pie plot of house owner\n","plt.figure(figsize =(7, 7))\n","df['house_owner'].value_counts().head(10).plot.pie(autopct='%1.1f%%')\n","\n","# Unsquish the pie.\n","import matplotlib.pyplot as plt\n","plt.gca().set_aspect('equal')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["[](http://)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Percentage of null values in house owner\n","(df.isnull().sum() / df.shape[0] * 100)['house_owner']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### The most house owner are owner, than we can fill missing values with house owner attribute"]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff['house_owner'] = dff['house_owner'].fillna(df.mode()['house_owner'][0])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Pie plot of age\n","plt.figure(figsize =(7, 7))\n","df['age'].value_counts().head(10).plot.pie(autopct='%1.1f%%')\n","\n","# Unsquish the pie.\n","import matplotlib.pyplot as plt\n","plt.gca().set_aspect('equal')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Percentage of null values in age\n","(df.isnull().sum() / df.shape[0] * 100)['age']"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff = dff.dropna(subset=['age'])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Pie plot of child\n","plt.figure(figsize =(7, 7))\n","df['child'].value_counts().head(10).plot.pie(autopct='%1.1f%%')\n","\n","# Unsquish the pie.\n","import matplotlib.pyplot as plt\n","plt.gca().set_aspect('equal')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Percentage of null values in child\n","(df.isnull().sum() / df.shape[0] * 100)['child']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### We don't have dominant categories in 'child', then we can´t fill the missing values. therefore, it is reasonable to disregard the 'child' column."]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff = dff.drop('child', axis=1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Pie plot marriage\n","plt.figure(figsize =(7, 7))\n","df['marriage'].value_counts().head(10).plot.pie(autopct='%1.1f%%')\n","\n","# Unsquish the pie.\n","import matplotlib.pyplot as plt\n","plt.gca().set_aspect('equal')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Percentage of null values in marriage\n","(df.isnull().sum() / df.shape[0] * 100)['marriage']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### More than 80% marriage are marriage, then we can fill missing values with marriage attribute"]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff['marriage'] = dff['marriage'].fillna(dff.mode()['marriage'][0])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Pie plot gender\n","plt.figure(figsize =(7, 7))\n","df['gender'].value_counts().head(10).plot.pie(autopct='%1.1f%%')\n","\n","# Unsquish the pie.\n","import matplotlib.pyplot as plt\n","plt.gca().set_aspect('equal')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Percentage of null values in gender\n","(df.isnull().sum() / df.shape[0] * 100)['gender']"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Pie plot education\n","plt.figure(figsize =(7, 7))\n","df['education'].value_counts().head(10).plot.pie(autopct='%1.1f%%')\n","\n","# Unsquish the pie.\n","import matplotlib.pyplot as plt\n","plt.gca().set_aspect('equal')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Percentage of null values in education\n","(df.isnull().sum() / df.shape[0] * 100)['education']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Since we have small amounts of missing values in the 'education' and 'gender' columns, then we simply drop them."]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff = dff.dropna(subset=['gender', 'education'])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# checking data cleaning\n","dff.isnull().sum()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### No more missing values"]},{"metadata":{},"cell_type":"markdown","source":["# 5. <a id='details'>Feature Engineering of dataset columns"]},{"metadata":{},"cell_type":"markdown","source":["### We started converting the data set columns that are of the object type into numeric values"]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff.dtypes"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Firts coverting  the hierarchy  columns "]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Converting flag and online features to binary integer\n","dff['flag'] = dff['flag'].apply(lambda value: 1 if value == 'Y' else 0)\n","dff['online'] = dff['online'].apply(lambda value: 1 if value == 'Y' else 0)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Converting education to integer\n","dff['education'] = dff['education'].apply(lambda value: int(value[0]) + 1 )"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Converting age to integer\n","dff['age'] = dff['age'].apply(lambda value: int(value[0]) - 1 )"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Converting mortgage to integer\n","dff['mortgage'] = dff['mortgage'].apply(lambda value: int(value[0]))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#fam_income label dictionary\n","dict_fam_income_label = {}\n","for i, char in enumerate(sorted(dff['fam_income'].unique().tolist())):\n","    dict_fam_income_label[char] = i + 1"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff['fam_income'] = dff['fam_income'].apply(lambda value: dict_fam_income_label[value])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Now, we deal of the columns with dummy variables"]},{"metadata":{"trusted":true},"cell_type":"code","source":["dummy_features = ['gender', 'customer_psy', 'occupation', 'house_owner', 'region', 'marriage']"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def apply_dummy(dff, i, drop_first=True):\n","\n","\n","    return pd.concat([dff, pd.get_dummies(dff[i], prefix=i, drop_first=drop_first)], axis=1).drop(i, axis=1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Converting dummy features in numerical values\n","for i in dummy_features:\n","    dff = apply_dummy(dff, i)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["dff.dtypes"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### All columns contain numerical values, but note that we have many more columns now, it is a price that we have to pay"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Heatmap of correlation\n","plt.figure(figsize=(14,14))\n","sns.heatmap(dff.corr())\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["###  Looking the heatmap of correlation we can see the most variables exhibit low positive and negative correlation. Remembering tha positive correlation can be definide like: if the value of one of the variables increases, the value of the other variable increases as well. In case negative correlation the value of one variable decreases with the other’s increasing and vice-versa."]},{"metadata":{},"cell_type":"markdown","source":["# 6. <a id='details'> Using machine learning to predict heart disease"]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Splitting the dataset into features and target\n","y0 = dff[\"flag\"]\n","x0 = dff.drop(\"flag\", axis = 1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Splitting the data into test data and training data\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x0, y0, test_size = 0.3)\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["accuracy_list = []"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Decision Tree Classifier\n","\n","dt_clf = DecisionTreeClassifier(max_leaf_nodes=10, random_state=30, criterion='entropy')\n","dt_clf.fit(x_train, y_train)\n","dt_pred = dt_clf.predict(x_test)\n","dt_acc = dt_clf.score(x_test,y_test)\n","accuracy_list.append(100*dt_acc)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(Fore.GREEN + \"Accuracy of Decision Tree Classifier is : \", \"{:.2f}%\".format(100* dt_acc))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","plt.figure(figsize = (8, 8))\n","mat = confusion_matrix(y_test, dt_pred)\n","sns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\n","plt.title(\"Decision Tree Clasifier - Confusion Matrix\")\n","plt.xticks(range(2), [\"0\",\"1\"], fontsize=16)\n","plt.yticks(range(2), [\"0\",\"1\"], fontsize=16)\n","plt.xlabel(\"true label\")\n","plt.ylabel(\"predicted label\");"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# K Neighbors Classifier\n","\n","kn_clf = KNeighborsClassifier(n_neighbors=6)\n","kn_clf.fit(x_train, y_train)\n","kn_pred = kn_clf.predict(x_test)\n","kn_acc = kn_clf.score(x_test,y_test)\n","accuracy_list.append(100*kn_acc)\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(Fore.GREEN + \"Accuracy of K Neighbors Classifier is : \", \"{:.2f}%\".format(100* kn_acc))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Confusion matrix of  K Neighbors Classifier\n","from sklearn.metrics import confusion_matrix\n","plt.figure(figsize = (8, 8))\n","mat = confusion_matrix(y_test, kn_pred)\n","sns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\n","plt.xlabel(\"true label\")\n","plt.ylabel(\"predicted label\")\n","plt.title(\"K Neighbors Classifier - Confusion Matrix\")\n","plt.xticks(range(2), [\"0\",\"1\"], fontsize=16)\n","plt.yticks(range(2), [\"0\",\"1\"], fontsize=16);"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# RandomForestClassifier\n","r_clf = RandomForestClassifier(max_features=0.5, max_depth=15, random_state=1)\n","r_clf.fit(x_train, y_train)\n","r_pred = r_clf.predict(x_test)\n","r_acc = r_clf.score(x_test,y_test)\n","accuracy_list.append(100*r_acc)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(Fore.GREEN + \"Accuracy of Random Forest Classifier is : \", \"{:.2f}%\".format(100* r_acc))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Confusion matrix of Random Forest Classifier \n","from sklearn.metrics import confusion_matrix\n","plt.figure(figsize = (8, 8))\n","mat = confusion_matrix(y_test, r_pred)\n","sns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\n","plt.xlabel(\"true label\")\n","plt.ylabel(\"predicted label\")\n","plt.title(\"Random Forest Classifier - Confusion Matrix\")\n","plt.xticks(range(2), [\"0\",\"1\"], fontsize=16)\n","plt.yticks(range(2), [\"0\",\"1\"], fontsize=16);"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# GradientBoostingClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","gradientboost_clf = GradientBoostingClassifier(max_depth=2, random_state=4)\n","gradientboost_clf.fit(x_train,y_train)\n","gradientboost_pred = gradientboost_clf.predict(x_test)\n","gradientboost_acc = gradientboost_clf.score(x_test,y_test)\n","accuracy_list.append(100*gradientboost_acc)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(Fore.GREEN + \"Accuracy of Gradient Boosting is : \", \"{:.2f}%\".format(100* gradientboost_acc))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Confusion matrix of Gradient Boosting\n","from sklearn.metrics import confusion_matrix\n","plt.figure(figsize = (8, 8))\n","mat = confusion_matrix(y_test, gradientboost_pred)\n","sns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\n","plt.xlabel(\"true label\")\n","plt.ylabel(\"predicted label\")\n","plt.title(\" Gradient Boosting - Confusion Matrix\")\n","plt.xticks(range(2), [\"0\",\"1\"], fontsize=16)\n","plt.yticks(range(2), [\"0\",\"1\"], fontsize=16);"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["from sklearn.naive_bayes import GaussianNB\n","gaussian = GaussianNB()\n","gaussian.fit(x_train, y_train)\n","gaussian_pred = gaussian.predict(x_test)\n","gaussian_acc = gaussian.score(x_test,y_test)\n","accuracy_list.append(100*gaussian_acc)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(Fore.GREEN + \"Accuracy of Gradient Boosting is : \", \"{:.2f}%\".format(100* gaussian_acc))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Confusion matrix of GaussianNB\n","from sklearn.metrics import confusion_matrix\n","plt.figure(figsize = (8, 8))\n","mat = confusion_matrix(y_test, gaussian_pred)\n","sns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\n","plt.xlabel(\"true label\")\n","plt.ylabel(\"predicted label\")\n","plt.title(\"GaussianNB - Confusion Matrix\")\n","plt.xticks(range(2), [\"0\",\"1\"], fontsize=16)\n","plt.yticks(range(2), [\"0\",\"1\"], fontsize=16);"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model_list = ['DecisionTree', 'KNearestNeighbours', 'RandomForest', 'GradientBooster', 'GaussianNB']"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plt.rcParams['figure.figsize']=20,8\n","sns.set_style('darkgrid')\n","ax = sns.barplot(x=model_list, y=accuracy_list, palette = \"vlag\", saturation =2.0)\n","plt.xlabel('Classifier Models', fontsize = 20 )\n","plt.ylabel('% of Accuracy', fontsize = 20)\n","plt.title('Accuracy of different Classifier Models', fontsize = 20)\n","plt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\n","plt.yticks(fontsize = 12)\n","for i in ax.patches:\n","    width, height = i.get_width(), i.get_height()\n","    x, y = i.get_xy() \n","    ax.annotate(f'{round(height,2)}%', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### We use five machine learning algorithms to predict whether a customer is likely to buy a particular product or not based on various information about them. The best performing algorithms were GradientBooster and RandomForest with efficiency around 69%. Since the target variable represents a generic product so that we can apply our predictive models to any particular product we want to analyze. As the positive and negative correlations between the variables are not very large, it directly implies the model's prediction efficiency. We can conclude that depending on the correlations, we can obtain great prediction efficiency with the machine learning models."]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.8.5-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}